{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1.\n",
    "\n",
    "### Collect Images For Face Recognition using harcascade for traing dataset in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17940\\24802494.py:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name for collecting training samplesVaibhav\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img, 1.1, 4)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        x=x-10\n",
    "        y=y-10\n",
    "        cropped_face = img[y:y+h+50, x:x+w+50]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "name = input(\"enter the name for collecting training samples\")\n",
    "\n",
    "## creating a path for training data \n",
    "parent_dir = \"C://Users//Admin//Training basket//Computer vision//Datasets//Train\"\n",
    "path = os.path.join(parent_dir , name)\n",
    "os.mkdir(path)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        #face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        \n",
    "        file_name_path = './Datasets/Train/'+ name + \"//\" + str(count) + '.jpg'\n",
    "        \n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0),2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        \n",
    "    if cv2.waitKey(1) == 27 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2. \n",
    "\n",
    "### Collect Images For Face Recognition using Dlib for training dataset in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17940\\2062338946.py:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name for collecting training samplesVaibhav\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        x=x-10\n",
    "        y=y-10\n",
    "        cropped_face = img[y:y+h+50, x:x+w+50]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "name = input(\"enter the name for collecting training samples\")\n",
    "\n",
    "## creating a path for training data \n",
    "parent_dir = \"C://Users//Admin//Training basket//Computer vision//Datasets//Test\"\n",
    "path = os.path.join(parent_dir , name)\n",
    "os.mkdir(path)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        #face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        \n",
    "        file_name_path = './Datasets/Test/'+ name + \"//\" + str(count) + '.jpg'\n",
    "        \n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2.\n",
    "### Collect Images For Face Recognition using Dlib for testing dataset in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import os\n",
    "\n",
    "cap = cv2.VideoCapture('rtsp://admin:Fifty@123@192.168.0.35:554/cam/realmonitor?channel=1&subtype=0&unicast=true&proto=Onvif')\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "#detector = dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")\n",
    "#predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "\n",
    "_, frame = cap.read()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "name = input(\"enter the name for collecting training samples : \")\n",
    "\n",
    "## creating a path for training data \n",
    "parent_dir = \"C:\\\\Users\\\\prem\\\\New_project\\\\Datasets\\\\Test\"\n",
    "path = os.path.join(parent_dir , name)\n",
    "os.mkdir(path)\n",
    "faces = detector(gray , 1)\n",
    "for face in faces:\n",
    "    x1 = face.left()\n",
    "    y1 = face.top()\n",
    "    x2 = face.right()\n",
    "    y2 = face.bottom()\n",
    "        #cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "# access a ip camera \n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from ip camera input \n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(frame, (400, 400))\n",
    "        #face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        \n",
    "        file_name_path = './Datasets/Test/'+ name + \"//\" + str(count) + '.jpg'\n",
    "        \n",
    "        \n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2. \n",
    "\n",
    "###  Store images in Mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mongoengine import connect \n",
    "connect(\"Datasets\" , host = \"127.0.0.1\", port = 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.Datasets\n",
    "Train = db.Train\n",
    "Test = db.Test\n",
    "name = input(\"please enter your name : \")\n",
    "\n",
    "for i in range(1,101): \n",
    "    \n",
    "    im = Image.open(\"C://Users//premb//New_project//Datasets//Train//\"+ name + \"//\" + str(1) + \".jpg\")\n",
    "\n",
    "    image_bytes = io.BytesIO()\n",
    "    im.save(image_bytes, format='JPEG')\n",
    "\n",
    "    image = {\n",
    "            'data': image_bytes.getvalue()\n",
    "            }\n",
    "\n",
    "    image_id = Test.insert_one(image).inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read images from mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson.binary import Binary\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.Datasets\n",
    "Train = db.Train\n",
    "image = Train.find_one()\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    pil_img = Image.open(io.BytesIO(image['data']))\n",
    "    plt.imshow(pil_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.testdb\n",
    "images = db.images\n",
    "\n",
    "im = Image.open(\"C://Users//premb//New_project//Datasets//Train//Prem//1.jpg\")\n",
    "\n",
    "image_bytes = io.BytesIO()\n",
    "im.save(image_bytes, format='JPEG')\n",
    "\n",
    "image = {\n",
    "    'data': image_bytes.getvalue()\n",
    "}\n",
    "\n",
    "image_id = images.insert_one(image).inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson.binary import Binary\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.testdb\n",
    "images = db.images\n",
    "image = images.find_one()\n",
    "\n",
    "pil_img = Image.open(io.BytesIO(image['data']))\n",
    "plt.imshow(pil_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
